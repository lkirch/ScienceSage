from config.config import OPENAI_API_KEY, QDRANT_URL, QDRANT_COLLECTION
from openai import OpenAI
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue
from app.prompts import get_system_prompt, get_user_prompt
from loguru import logger

client = OpenAI(api_key=OPENAI_API_KEY)
qdrant = QdrantClient(url=QDRANT_URL)

def embed_text(text: str):
    """Embed text with OpenAI."""
    logger.debug(f"Embedding text: {text[:50]}...")  # Log first 50 chars
    try:
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        logger.debug("Embedding successful")
        return response.data[0].embedding
    except Exception as e:
        logger.error(f"Embedding failed: {e}")
        raise

def retrieve_answer(query: str, topic: str, level: str):
    """Retrieve top context from Qdrant and generate GPT answer."""
    logger.info(f"Retrieving answer for query='{query[:50]}...', topic='{topic}', level='{level}'")
    try:
        vector = embed_text(query)
        logger.debug(f"Query vector (len={len(vector)}): {vector}")  # Log the query vector
    except Exception as e:
        logger.error(f"Failed to embed query: {e}")
        raise

    try:
        results = qdrant.query_points(
            collection_name=QDRANT_COLLECTION,
            query=vector,
            limit=3,
            query_filter=Filter(
                must=[FieldCondition(key="topic", match=MatchValue(value=topic))]
            )
        )
        logger.debug(f"Qdrant returned {len(results.points)} points")
    except Exception as e:
        logger.error(f"Qdrant query failed: {e}")
        raise

    contexts = [p.payload.get("text") for p in results.points]
    if not contexts:
        logger.warning("No context found for query")
    context_text = "\n\n".join(contexts) if contexts else "No additional context found."

    system_prompt = get_system_prompt(topic, level)
    user_prompt = get_user_prompt(query, context_text)

    try:
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
        )
        logger.info("Answer generated by OpenAI")
    except Exception as e:
        logger.error(f"OpenAI completion failed: {e}")
        raise

    answer = completion.choices[0].message.content
    return answer,